{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:  \n",
    "\n",
    "How to handle data processing if your dataset(200GB) is bigger than your memory size (64GB)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  save npy took 16.20359s\n",
      "  raw data is 19.53125 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "shape = (20000,64,64,64)\n",
    "l = reduce(lambda x,y:x*y, shape)\n",
    "data = np.arange(l, dtype=np.float32).reshape(shape)\n",
    "\n",
    "\n",
    "npy_file = './test_chunks.npy'\n",
    "time_start = time.clock()\n",
    "np.save(npy_file, data)\n",
    "print('  save npy took {}s'.format(time.clock() - time_start))\n",
    "print('  raw data is {} GB'.format(data.nbytes/1024/1024/1024.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving chunks=True took 75.789275s\n",
      "read ./test_chunks_true.hdf5 0.000770999999986s\n",
      "load 128 slices 31.665066s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "file_chunks_true = './test_chunks_true.hdf5'\n",
    "\n",
    "def save_default_chunk():\n",
    "    time_start = time.clock()\n",
    "    with h5py.File(file_chunks_true, 'w') as outfile:\n",
    "        dset = outfile.create_dataset('test_data', data=data, chunks=True, compression='lzf')\n",
    "        print('saving chunks=True took {}s'.format(time.clock() - time_start))\n",
    "\n",
    "\n",
    "def read(f):\n",
    "    data = h5py.File(f, 'r')\n",
    "    return data['test_data']\n",
    "\n",
    "def load(f):\n",
    "    time_start = time.clock()\n",
    "    data = read(f)\n",
    "    print('read {} {}s'.format(f, time.clock() - time_start))\n",
    "\n",
    "    time_start = time.clock()\n",
    "    num_slices = 128\n",
    "    import random\n",
    "    r = random.sample(range(1, shape[0]), num_slices)\n",
    "    r.sort()\n",
    "    vol = data[r,:,:,:]\n",
    "    print('load {} slices {}s'.format(num_slices, time.clock() - time_start))\n",
    "\n",
    "save_default_chunk()   # 73s to save\n",
    "load(file_chunks_true)   # takes 322s to load slice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /data/luna16/test_chunks_manual.hdf5 53.264433s\n",
      "read ./test_chunks_manual.hdf5 0.000420000000076s\n",
      "load 128 slices 7.777437s\n"
     ]
    }
   ],
   "source": [
    "file_manual_chunks = './test_chunks_manual.hdf5'  # manually set chunk_size\n",
    "\n",
    "def save_manual_chunk():    \n",
    "    time_start = time.clock()\n",
    "    with h5py.File(file_manual_chunks, 'w') as outfile:\n",
    "        dset = outfile.create_dataset('test_data', data=data, chunks=(1,64,64,64), compression='lzf')  #manual chunks\n",
    "        print('saving {} {}s'.format(file, time.clock() - time_start))\n",
    "\n",
    "save_manual_chunk()   # 55s to save\n",
    "load(file_manual_chunks)   # takes 68s to load 10*128*(64,64,64) slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 jack jack 635M  7月  7 17:25 test_chunks_manual.hdf5\r\n",
      "-rw-rw-r-- 1 jack jack  20G  7月  7 17:22 test_chunks.npy\r\n",
      "-rw-rw-r-- 1 jack jack 5.4G  7月  7 17:24 test_chunks_true.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl *chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Contact:  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
